{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNePMYAj1prQ/K8TC03ZnIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52201/Gen-AI/blob/main/GNAI_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import mutual_info_regression, RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/archive.zip')\n",
        "\n",
        "# Print the actual column names to verify\n",
        "print(df.columns)\n",
        "\n",
        "# Select features and target\n",
        "# Use actual column names from the printed output,\n",
        "# adjusting for case sensitivity if necessary\n",
        "features = df.drop(columns=df.columns[df.columns.str.startswith('PM')], axis=1)\n",
        "target = df[df.columns[df.columns.str.startswith('PM')]]\n",
        "\n",
        "\n",
        "# One-hot encode categorical features\n",
        "non_numeric_cols = features.select_dtypes(include=['object', 'category']).columns\n",
        "features = pd.get_dummies(features, columns=non_numeric_cols)\n",
        "\n",
        "# Train-test split\n",
        "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
        "    features, target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Build the ANN model\n",
        "def build_ann(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(3))  # 3 output units for PM2.5, PM10, and NO2\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Correlation Thresholding\n",
        "cor_matrix = X_train_full.corr()\n",
        "high_corr_vars = set()\n",
        "for i in range(len(cor_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(cor_matrix.iloc[i, j]) > 0.85:\n",
        "            high_corr_vars.add(cor_matrix.columns[i])\n",
        "\n",
        "X_train_corr = X_train_full.drop(columns=high_corr_vars)\n",
        "X_test_corr = X_test_full[X_train_corr.columns]\n",
        "\n",
        "# Scale features and target\n",
        "scaler_corr = StandardScaler()\n",
        "X_train_corr_scaled = scaler_corr.fit_transform(X_train_corr)\n",
        "X_test_corr_scaled = scaler_corr.transform(X_test_corr)\n",
        "\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train)\n",
        "y_test_scaled = target_scaler.transform(y_test)\n",
        "\n",
        "# Train model with correlation thresholding\n",
        "model_corr = build_ann(X_train_corr_scaled.shape[1])\n",
        "history_corr = model_corr.fit(X_train_corr_scaled, y_train_scaled, epochs=100, batch_size=16,\n",
        "                              validation_data=(X_test_corr_scaled, y_test_scaled), verbose=0)\n",
        "\n",
        "# Mutual Information Feature Selection\n",
        "mi_scores = np.zeros(X_train_full.shape[1])\n",
        "for i in range(y_train.shape[1]):\n",
        "    mi_scores += mutual_info_regression(X_train_full, y_train.iloc[:, i])\n",
        "mi_scores /= y_train.shape[1]\n",
        "\n",
        "mi_idx = np.argsort(mi_scores)[::-1][:10]\n",
        "X_train_mi = X_train_full.iloc[:, mi_idx]\n",
        "X_test_mi = X_test_full[X_train_mi.columns]\n",
        "\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_mi_scaled = scaler_mi.fit_transform(X_train_mi)\n",
        "X_test_mi_scaled = scaler_mi.transform(X_test_mi)\n",
        "\n",
        "# Train model with Mutual Information features\n",
        "model_mi = build_ann(X_train_mi_scaled.shape[1])\n",
        "history_mi = model_mi.fit(X_train_mi_scaled, y_train_scaled, epochs=10, batch_size=16,\n",
        "                          validation_data=(X_test_mi_scaled, y_test_scaled), verbose=0)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)\n",
        "rfe_selector = RFE(estimator=LinearRegression(), n_features_to_select=10)\n",
        "rfe_selector = rfe_selector.fit(X_train_full, y_train)\n",
        "X_train_rfe = X_train_full.loc[:, rfe_selector.support_]\n",
        "X_test_rfe = X_test_full[X_train_rfe.columns]\n",
        "\n",
        "scaler_rfe = StandardScaler()\n",
        "X_train_rfe_scaled = scaler_rfe.fit_transform(X_train_rfe)\n",
        "X_test_rfe_scaled = scaler_rfe.transform(X_test_rfe)\n",
        "\n",
        "# Train model with RFE features\n",
        "model_rfe = build_ann(X_train_rfe_scaled.shape[1])\n",
        "history_rfe = model_rfe.fit(X_train_rfe_scaled, y_train_scaled, epochs=10, batch_size=16,\n",
        "                            validation_data=(X_test_rfe_scaled, y_test_scaled), verbose=0)\n",
        "\n",
        "# Plot history for each model\n",
        "def plot_history(history, title):\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_corr, 'Model with Correlation Thresholding')\n",
        "plot_history(history_mi, 'Model with Mutual Information')\n",
        "plot_history(history_rfe, 'Model with RFE')\n",
        "\n",
        "# Evaluate RMSE for each model\n",
        "def evaluate_rmse(model, X_test_scaled, y_test_scaled, title):\n",
        "    y_pred_scaled = model.predict(X_test_scaled)\n",
        "    y_pred = target_scaler.inverse_transform(y_pred_scaled)\n",
        "    y_true = target_scaler.inverse_transform(y_test_scaled)\n",
        "    rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
        "    print(f\"{title} - Final RMSE: {rmse:.4f}\")\n",
        "\n",
        "evaluate_rmse(model_corr, X_test_corr_scaled, y_test_scaled, \"Correlation Thresholding\")\n",
        "evaluate_rmse(model_mi, X_test_mi_scaled, y_test_scaled, \"Mutual Information\")\n",
        "evaluate_rmse(model_rfe, X_test_rfe_scaled, y_test_scaled, \"RFE\")\n"
      ],
      "metadata": {
        "id": "ClOYNGjgKu-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}